
### 样本不均衡问题总结

&emsp;&emsp;无论是在ctr预估，还是文本分类的问题中，都会涉及到样本不均衡的问题，今天查看了一些相关资料，对样本不均衡问题做个笔记。

#### 1. 模型如何评价

- ROC下的曲线：横坐标是false positive rate，纵坐标是true postitve rate
- PR下的曲线：横坐标是查全率，纵坐标是查准率
- Precision@Rank k:top k 的准确率

&emsp;&emsp;评价指标资料如下：

- [ROC、K-S 曲线、Lift 曲线、PR 曲线](https://zhuanlan.zhihu.com/p/39435695)
- [Precision@N](https://blog.csdn.net/mch2869253130/article/details/100884758)
- [roc曲线怎么画](https://www.zhihu.com/question/22844912)
- [mAP（mean average precision）平均精度均值](https://www.jianshu.com/p/82be426f776e)

#### 2. 如何解决问题

&emsp;&emsp;处理数据不平衡的问题，传统的思路还是使用过采样和欠采样

- 1.过采样只是单纯的重复了正例，会过分强调已有的正例，如果其中重复的正例标记错误或者是噪音，错误会被成倍的放大，因此最大的风险就是对正例过拟合。
- 2.欠采样抛弃了大部分反例数据，弱化了部分反例的影响，可能会造成偏差很大的模型，另一种常见的做法是反复做欠采样，但也存在风险：
  - 训练多个模型有过大的开销
  - 正例被反复使用，和过采样一样，很容易造成模型的过拟合。
- 3.SMOTE和过采样有明显的不同，因为不单纯是重复正例，而是在局部区域通过K-近邻生成了新的正例，相较于简单的过采样，SMOTE有如下特点：
  - 降低了过拟合风险
  - 对于噪音的抵抗性更强
  - 运算开销增大，可能会生成一些可疑的点
 
SMOTE补充描述

&emsp;&emsp;考虑少数类的一个样本i，其特征向量为$x_i,i \in \{1,...,T\}$:

- 1.首先从少数类的全部T个样本中找到样本$x_i$的k个近邻(欧式距离)，记为$x_{i(near)},near \in \{1,...,k\}$
- 2.然后从k个近邻中随机选择一个样本$x_i(nn)$，再生成一个0到1之间的随机数a,从而合成一个新样本$x_{i1}$:
$$x_{i1} = x_i + a * (x_{i(nn)} - x_i)$$
- 3.将步骤2重复进行N次，从而可以合成N个新的样本



#### 3. 采样法归纳总结

- 1.使用采样方法（过采样和欠采样）一般可以提升模型的泛化能力，但是有一定的过拟合风险，应搭配使用正则化模型
- 2.过采样的结果较为稳定，SMOTE也是
- 3.过采样大部分时候比欠采样效果好，具体问题具体分析
- 4.和采样法搭配使用的模型最好可以很好的处理过拟合


#### 4. 参考资料

- [【小夕精选】如何优雅而时髦的解决不均衡分类问题](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484993&idx=1&sn=0bd32089a638e5a1b48239656febb6e0&chksm=970c2e97a07ba7818d63dddbb469486dccb369ecc11f38ffdea596452b9e5bf65772820a8ac9&token=407616831&lang=zh_CN#rd)
- [数据挖掘中常见的「异常检测」算法有哪些？](https://www.zhihu.com/question/280696035/answer/417091151)
- [欠采样（undersampling）和过采样（oversampling）会对模型带来怎样的影响？](https://www.zhihu.com/question/269698662/answer/352279936)
- [如何处理数据中的「类别不平衡」？](https://zhuanlan.zhihu.com/p/32940093)
- [机器学习 —— 类不平衡问题与SMOTE过采样算法](https://www.cnblogs.com/Determined22/p/5772538.html)
- [SMOTE算法(人工合成数据)](https://blog.csdn.net/jiede1/article/details/70215477)
